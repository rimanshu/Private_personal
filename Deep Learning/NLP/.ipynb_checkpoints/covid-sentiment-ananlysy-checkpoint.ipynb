{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_hub\n",
    "!pip install tensorflow_text\n",
    "# !pip intall bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "# import bert\n",
    "from tensorflow.keras.models import  Model\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "print(\"TensorFlow Version:\",tf.__version__)\n",
    "print(\"Hub version: \",hub.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\"\n",
    "tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_src = pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_train.csv', index_col='UserName', encoding='ISO-8859-1')\n",
    "df_test_src = pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_test.csv', index_col='UserName', encoding='ISO-8859-1')\n",
    "\n",
    "df = pd.concat([df_train_src, df_test_src], sort=False, axis=0, ignore_index=True)\n",
    "df.drop(['ScreenName', 'TweetAt', 'Location'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Sentiment']=='Extremely Positive', 'Sentiment'] = 'Positive'\n",
    "df.loc[df['Sentiment']=='Extremely Negative', 'Sentiment'] = 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.index.isin(df_train_src.index)]\n",
    "df_test = df[df.index.isin(df_test_src.index)]\n",
    "\n",
    "# df_train = df.loc[df_train_src.index][['Tweet', 'Sentiment']]\n",
    "# df_test = df.loc[df_test_src.index][['Tweet', 'Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    \n",
    "    text_input = tf.keras.layers.Input(\n",
    "        shape=(), dtype=tf.string, name='text')\n",
    "    \n",
    "    preprocessing_layer = hub.KerasLayer(\n",
    "        tfhub_handle_preprocess, name='preprocessing')\n",
    "    \n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(\n",
    "        tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    \n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(\n",
    "        3, activation='softmax', name='classifier')(net)\n",
    "    model = tf.keras.Model(text_input, net)\n",
    "    \n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    metric = tf.metrics.CategoricalAccuracy('accuracy')\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=5e-05, epsilon=1e-08, decay=0.01, clipnorm=1.0)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=loss, metrics=metric)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = build_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df_train,train_size=0.7,random_state=0,stratify=df_train['Sentiment'])\n",
    "y_train, X_train = train['Sentiment'], train.drop(['Sentiment'], axis=1)\n",
    "y_valid, X_valid = valid['Sentiment'], valid.drop(['Sentiment'], axis=1)\n",
    "y_train_c = tf.keras.utils.to_categorical(y_train.astype('category').cat.codes.values, num_classes=3)\n",
    "y_valid_c = tf.keras.utils.to_categorical(y_valid.astype('category').cat.codes.values, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = classifier_model.fit(\n",
    "    x=X_train['OriginalTweet'].values,\n",
    "    y=y_train_c,\n",
    "    validation_data=(X_valid['OriginalTweet'].values, y_valid_c),\n",
    "    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.set_context(\"paper\", font_scale=2) \n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(121)\n",
    "sns.lineplot(ax=ax1, data=history.history['accuracy'])\n",
    "sns.lineplot(ax=ax1, data=history.history['val_accuracy'])\n",
    "ax1.set(\n",
    "    title=f\"Model accuracy\",\n",
    "    xlabel=\"epoch\",\n",
    "    ylabel=\"accuracy\"\n",
    ")\n",
    "ax1.legend(['train', 'test'], loc='upper left')\n",
    "ax2 = fig.add_subplot(122)\n",
    "sns.lineplot(ax=ax2, data=history.history['loss'])\n",
    "sns.lineplot(ax=ax2, data=history.history['val_loss'])\n",
    "ax2.set(\n",
    "    title=f\"Model loss\",\n",
    "    xlabel=\"epoch\",\n",
    "    ylabel=\"loss\"\n",
    ")\n",
    "ax2.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_c = tf.keras.utils.to_categorical(\n",
    "    df_test['Sentiment'].astype('category').cat.codes.values, num_classes=3)\n",
    "\n",
    "e = classifier_model.evaluate(x=df_test['OriginalTweet'].values, y=y_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"BERT Accuracy: {e[1]}\")\n",
    "y_proba_bert = classifier_model.predict(df_test['OriginalTweet'].values)\n",
    "y_pred_bert = np.argmax(y_proba_bert, axis=1)\n",
    "\n",
    "y_true = df_test['Sentiment'].astype('category').cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "target_names = ['Negative', 'Neutral', 'Positive']\n",
    "cf_matrix = confusion_matrix(y_true, y_pred_bert)\n",
    "sns.heatmap(\n",
    "    cf_matrix/np.sum(cf_matrix),\n",
    "    annot=True, fmt='.2%', cmap='Blues',\n",
    "    xticklabels=target_names,\n",
    "    yticklabels=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Report for BERT\n",
    "print(classification_report(y_true, y_pred_bert, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
