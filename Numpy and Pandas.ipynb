{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Pandas and Numpy Tutorials --- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important links to be followed \n",
    "\n",
    "https://mlcourse.ai/articles/topic1-exploratory-data-analysis-with-pandas/\n",
    "\n",
    "https://stackabuse.com/beginners-tutorial-on-the-pandas-python-library/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series and dataframe - Series is one dimentional array and dataframe is two dimentional data structure. \n",
    "#Both can store any datatype but in series we can change the values but not change the size. dataframe can change both the value and size.\n",
    "#Dataframe is row column data structure. Two series will make one dataframe. Dataframe can make from series, list,dic,tuple etc. Series is smilar to python list.\n",
    "\n",
    "\n",
    "items = [['Phone', 2000], ['TV', 1500], ['Radio', 800]]\n",
    "df=pd.DataFrame(items,columns=['items','price'],dtype=float)\n",
    "df.head()\n",
    "df.describe\n",
    "\n",
    "#DataFrames can be indexed by column name (label) or row name (index) or by the serial number of a row. The loc method is used for indexing by name, while iloc() is used for indexing by number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new way to read multiple excel files.\n",
    "with pd.ExcelFile('worker.xlsx') as x:\n",
    "    s1=pd.read_excel(x,'sheet1')\n",
    "    s2=pd.read_excel(x,'sheet2')\n",
    "    \n",
    "print('sheet1:',s1)\n",
    "print('sheet2:',s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split function trick\n",
    "\n",
    "str1=\"Rimanshu Mangal\"\n",
    "\n",
    "First_Name,Second_name =str1.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the dataframe\n",
    "pd.merge(df1,df2,on='subject_id', how='inner', sort=False)\n",
    "\n",
    "#Concatenate the dataframe means we add the one dataset to another.\n",
    "pd.concat(df1,df2)\n",
    "\n",
    "#.merge() can only use columns (plus rows indices) and it is semantically suitable for database-style operations. .concat() can be used with either axis, using only indices\n",
    "\n",
    "#merge() is used to combine two (or more) dataframes on the basis of values of common columns (indices can also be used, use left_index=True and/or right_index=True), and concat() is used to append one (or more) dataframes one below the other (or sideways, depending on whether the axis option is set to 0 or 1).\n",
    "\n",
    "#join() is used to merge 2 dataframes on the basis of the index; instead of using merge() with the option left_index=True we can use join().\n",
    "\n",
    "#pd.concat takes an Iterable as its argument. Hence, it cannot take DataFrames directly as its argument. Also Dimensions of the DataFrame should match along axis while concatenating.\n",
    "\n",
    "#pd.merge can take DataFrames as its argument, and is used to combine two DataFrames with same columns or index, which can't be done with pd.concat since it will show the repeated column in the DataFrame.\n",
    "\n",
    "#pd.concat has inner default and outer joins only, while pd.DataFrame.merge() has left, right, outer, innerdefault joins.\n",
    "\n",
    "#With pd.concat by default you are able to stack rows of multiple dataframes (axis=0) and when you set the axis=1 then you mimic the pd.DataFrame.merge() function.\n",
    "\n",
    "#These are the main differences between df.join() and df.merge():\n",
    "\n",
    "# Join will work on index while merge is not.\n",
    "\n",
    "#lookup on right table: df1.join(df2) always joins via the index of df2, but df1.merge(df2) can join to one or more columns of df2 (default) or to the index of df2 (with right_index=True).\n",
    "#lookup on left table: by default, df1.join(df2) uses the index of df1 and df1.merge(df2) uses column(s) of df1. That can be overridden by specifying df1.join(df2, on=key_or_keys) or df1.merge(df2, left_index=True).\n",
    "#left vs inner join: df1.join(df2) does a left join by default (keeps all rows of df1), but df.merge does an inner join by default (returns only matching rows of df1 and df2).\n",
    "\n",
    "# Join uses merge internally with indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping the datasets alongwith any column.\n",
    "\n",
    "df.groupby(by=grouping_columns)[columns_to_show].function()\n",
    "\n",
    "raw = {  \n",
    "    'Name': ['John', 'John', 'Grace', 'Grace', 'Benjamin', 'Benjamin', 'Benjamin',\n",
    "        'Benjamin', 'John', 'Alex', 'Alex', 'Alex'],\n",
    "    'Position': [2, 1, 1, 4, 2, 4, 3, 1, 3, 2, 4, 3],\n",
    "    'Year': [2009, 2010, 2009, 2010, 2010, 2010, 2011, 2012, 2011, 2013, 2013, 2012],\n",
    "    'Marks':[408, 398, 422, 376, 401, 380, 396, 388, 356, 402, 368, 378]\n",
    "}\n",
    "df=pd.DataFrame(raw)\n",
    "group= df.groupby('year')\n",
    "print(group.get_group(2010))\n",
    "\n",
    "columns_to_show = ['Total day minutes', 'Total eve minutes', \n",
    "                   'Total night minutes']\n",
    "\n",
    "df.groupby(['Churn'])[columns_to_show].agg([np.mean, np.std, np.min, \n",
    "                                            np.max])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Cross tab #############\n",
    "\n",
    "#Suppose we want to see how the observations in our sample are distributed in the context of two variables - Churn and International plan. To do so, we can build a contingency table using the crosstab method\n",
    "\n",
    "pd.crosstab(df['Churn'], df['Voice mail plan'], normalize=True) - #normaize for %\n",
    "\n",
    "pd.crosstab(df['Churn'], df['International plan'], margins=True) - #margin to show total also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Map and apply function ###########\n",
    "\n",
    "# The apply method can also be used to apply a function to each row. To do this, specify axis=1. Lambda functions are very convenient in such scenarios. \n",
    "\n",
    "# The map method can be used to replace values in a column by passing a dictionary of the form {old_value: new_value} as its argument:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NumPy library is a popular Python library used for scientific computing applications, and is an acronym for \n",
    "# \"Numerical Python\". NumPy's operations are divided into three main categories: Fourier Transform and Shape Manipulation, \n",
    "# Mathematical and Logical Operations, and Linear Algebra and Random Number Generation. To make it as fast as possible, \n",
    "# NumPy is written in C and Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, in order to add 2 to each element in the list x, we have to traverse the entire list and add 2 to each element \n",
    "# individually. it can be one dimentional and two dimentional both.\n",
    "\n",
    "x = [2, 3, 4, 5, 6]\n",
    "y = [a + 2 for a in x]\n",
    "\n",
    "import numpy as np\n",
    "nums = np.array([2, 3, 4, 5, 6])\n",
    "nums2 = nums + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some basic functions in numpy.\n",
    "\n",
    "nums = np.arange(2, 7, 2) # start,1-end,step size.\n",
    "\n",
    "zeros = np.zeros((5, 4)) # Two dimentional Matrix or array wirh values zeros.\n",
    "ones = np.ones(5) # one dimentional array with values one.\n",
    "lin = np.linspace(1, 10, 10) # It will equally divided the values into 10 parts. start,end, and equall partition.\n",
    "idn = np.eye(4) #An identity matrix is a matrix with zeros across rows and columns except the diagonal.\n",
    "\n",
    "random = np.random.rand(2, 3) #The matrix contains uniform distribution of numbers between 0 and 1:\n",
    "random = np.random.randn(2, 3) # to create a matrix of random numbers with the normal\" distribution use the randn method\n",
    "random = np.random.randint(50,100,5) # start, end , number of integer you want.\n",
    "\n",
    "nums2 = nums.reshape(4, 4) # reshaping or changing the array from one dim to another dim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions in Numpy\n",
    "\n",
    "np.log()\n",
    "np.exp()\n",
    "np.sqrt()\n",
    "np.sin()\n",
    "np.dot() # for dot product\n",
    "np.max()\n",
    "np.min()\n",
    "np.argmin()\n",
    "np.argmax()\n",
    "np.linalg.inv(Y) # inverse of every element.\n",
    "np.linalg.det(X) # determinent of matrix\n",
    "np.trace(X) # The trace of a matrix is the sum of all the elements in the diagonal of a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some important functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda,map,filter and reduse function is maing object data structure so need to convert it.\n",
    "#Lambda function - A lambda operator or lambda function is used for creating small, one-time, anonymous function in Python.\n",
    "\n",
    "#lambda arguments : expression\n",
    "\n",
    "add = lambda x, y : x + y \n",
    "double = lambda x: 2*x\n",
    "print (add(2, 3)) # Output: 5\n",
    "\n",
    "# Map funcion -\n",
    "#map(function_object, iterable1, iterable2,...)\n",
    "map(multiply2, [1, 2, 3, 4])\n",
    "list_a = [1, 2, 3]\n",
    "list_b = [10, 20, 30]\n",
    "  \n",
    "map(lambda x, y: x + y, list_a, list_b) # Output: [11, 22, 33]\n",
    "\n",
    "# Filter function - Filtering the items from list or any datatype.\n",
    "\n",
    "#filter(function_object, iterable)\n",
    "\n",
    "a = [1, 2, 3, 4, 5, 6]\n",
    "filter(lambda x : x % 2 == 0, a) # Output: [2, 4, 6]\n",
    "\n",
    "#Reduse - It also return object type datastructure and works on f(f(m,n),p)\n",
    "\n",
    "n=[4,3,2,1]\n",
    "print(reduce(lambda x,y:x*y,n)) # ((4*3)*2)*1 \n",
    "\n",
    "#Zip function -\n",
    "#zip takes n number of iterables and returns list of tuples. it makes object type structure.\n",
    "\n",
    "\n",
    "list_a = [1, 2, 3, 4, 5]\n",
    "list_b = ['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "zipped_list = zip(list_a, list_b) # [(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd'), (5, 'e')]\n",
    "#zip can truncates the extra elements of list_b in the output.\n",
    "\n",
    "list_a = [1, 2, 3]\n",
    "list_b = ['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "zipped_list = zip(list_a, list_b)\n",
    "\n",
    "print (zipped_list) # [(1, 'a'), (2, 'b'), (3, 'c')]\n",
    "\n",
    "#Unzip a list of tuples\n",
    "zipper_list = [(1, 'a'), (2, 'b'), (3, 'c')]\n",
    " \n",
    "list_a, list_b = zip(*zipper_list)\n",
    "print (list_a) # (1, 2, 3)\n",
    "print (list_b) # ('a', 'b', 'c')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    4\n",
       "2    6\n",
       "3    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map can applied to eries in this way.\n",
    "import pandas as pd\n",
    "lis=[1, 2, 3, 4]\n",
    "ser=pd.Series(lis)\n",
    "ser.map(lambda x : x*2) #Output [2, 4, 6, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enumerate() method adds a counter to an iterable and returns it in a form of enumerate object\n",
    "#enumerate(iterable, start=0)\n",
    "\n",
    "l1 = [\"eat\",\"sleep\",\"repeat\"] \n",
    "s1 = \"geek\"\n",
    "\n",
    "print (\"Return type:\",type(obj1)) \n",
    "print (list(enumerate(l1)))\n",
    "\n",
    "cities=[jaipur,bangalore,mumbai,pune,noida]\n",
    "for i,city in enumerate(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 jaipur\n",
      "1 bangalore\n",
      "2 mumbai\n",
      "3 pune\n",
      "4 noida\n"
     ]
    }
   ],
   "source": [
    "cities=['jaipur','bangalore','mumbai','pune','noida']\n",
    "for i,cities in enumerate(cities):\n",
    "    print(i,cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
